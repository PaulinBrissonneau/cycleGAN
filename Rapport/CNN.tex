\documentclass{article}
\usepackage[utf8]{inputenc}

\title{CNN}
\author{valentinlaure }
\date{May 2020}

\begin{document}

\chapter{Les réseaux à convolutions}

\section{Présentation générale}

\subsection{Introduction}
L'architecture d'un multiperceptron se prête bien à des applications simplistes comme de la reconnaissance de chiffre. Cependant, dès que la complexité des données augmente ne serait-ce que légèrement, le MLP devient innefficace en un temps raisonnable pour pouvoir reconnaitre des objets . Heureusement, il existe une structure bien plus efficace qui est parfaitement adaptée à la reconnaissance d'image : le CNN (convolutional neural network). Dans cette partie, nous allons nous efforcer d'expliquer le fonctionnement de celui-ci ainsi que ses avantages. 

\subsection{Structure d'un CNN}
La structure d'un CNN se rapproche de celle d'un multiperceptron dans la mesure où celui-ci est aussi organisé sous forme de couches. Cependant, certaines couches, nommées couche de convolution, ont un fonctionnement radicalement différent de celui d'une couche dense. \\
\\
Voici l'architecture d'un CNN :

{insérer image architecture CNN}\\
\\
Comme on peut le voir, l'image en entrée est d'abord traitée par une succession de couches de convolutions suivies d'une couche de pooling. Ensuite ce processus se répéte un certain nombre de fois et finalement le résultat passe par une couche dense(plus rarement plusieurs) afin de donner la bonne classification.

\subsection{Principe général}
Le principe directeur se cachant derrière les couches de convolution est assez intuitif : on dispose d'un noyau(pattern) capable de reconnaître un motif en particulier. Il suffit alors de balayer l'image pixel par pixel(notion expliquée plus en détails ultérieurement) pour savoir où se trouvent précisément certains motifs sur l'image. En répétant ce procédé avec un grand nombre de noyaux différents, nous sommes dans la possibilité de pouvoir identifier la présence ou non de certains motifs caractéristiques de l'objet à reconnaître. \\
Nous disposons ainsi d'une "carte" des différents motifs qu'il nous est possible de réduire en taille(étape de pooling) pour réduire le nombre de calculs effectués. 
Le processus se répéte un certains nombre de fois jusqu'à ce que l'on considère que les données soient suffisamment bien réduites pour qu'un MLP puisse s'en charger. 

\section{Formalisation d'un CNN}

Une fois le principe directeur mis en évidence, nous pouvons nous atteler à la formalisation du CNN.

\subsection{Le produit de convolution : un outil indispensable}

Le coeur de l'efficacité d'un CNN repose sur le produit de convolution. On assimile l'image à une matrice notée $I$(nous la supposons pour l'instant en niveau de gris, de telle sorte que la matrice est en 2D mais la généralisation en 3D se fait aisément). De même, le noyau sera noté sous la forme d'une matrice $K$.
L'opération de convolution s'écrit alors : \\

$\forall (x,y) \in [|0,W_I|] \times [|0,H_I|]$,  $(N \otimes I)_{x,y} = \sum_{i=0}^{W_K} \sum_{j=0}^{H_K} K_{i,j} \times I_{x-i,y-j}$ \\
\\
Où l'on a posé $W_I,H_I$ la taille de l'image et $W_K,H_K$ la taille du noyau. \\
\\
Voici quelques exemples de l'effet du produit de convolution avec plusieurs noyaux :\\
\\
{insérer image chien de prairie}\\
\\
Ainsi, cette opération nous permet de mettre en évidence des motifs élémentaires en activant la case correspondante si le motif est présent au niveau de celle-ci.

\subsection{Le balayage de l'image : une histoire de Padding et de Stride}

Pour pouvoir évaluer toute l'image, il va falloir la balayer avec le noyau. De manière assez logique, on commence par le placer sur le coin supérieur gauche de l'image, puis on affectue un produit de convolution. Ensuite, il suffit de faire glisser latéralement le noyau d'un pixel et de répéter l'opération. Une fois au bout de la ligne, on descend d'un pixel et on repart à gauche. \\
Voici un exemple de balayage d'un noyau sur une image : \\
\\
{insérer image balayage image}\\
\\
On remarque alors que le résultat à une dimension plus petite que l'image d'origine : on a ici effectué ce que l'on appelle un \textbf{simple padding}. Cependant, on pourrait souhaiter que le résultat ait la même dimension : c'est du \textbf{same padding}. Pour cela, nous pouvons rajouter des gardes autour de l'image d'origine : on rajoute des zéros autour puis on effectue l'opération de convolution comme présenté sur cette image :\\
\\
{insérer image same padding}\\
\\
Il existe encore un paramètre permettant de personnaliser l'opération : le \textbf{stride}. Celui correspond au décalage à utiliser pour le noyau :\\
\\
{insérer image stride}\\
\\ 
L'avantage d'avoir un stride plus grand que 1 est aussi son désavantage : en effet il va permettre d'avoir un résultat en sortie de plus petite dimension mais en contrepartie, il y a une perte d'information.

\subsection{Généralisation en 3D}

Les images en couleurs peuvent être représentées par une matrice 3D de profondeur 3. Pour pouvoir gérer ce cas, nous prenons des noyaux de de la même profondeur que l'image, puis nous appliquons séparément le produit de convolution sur les profondeurs correspondantes, le résulat final n'étant que la somme des résultats sur chaque profondeur. Puisqu'un schéma vaut bien plus qu'un texte :\\
\\
{insérer image 3D}\\
\\


\end{document}
